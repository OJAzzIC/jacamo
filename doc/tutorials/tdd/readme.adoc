This tutorial explains how to test Jason agents in AgentSpeak, using a novel (as of 2022)
goal-oriented test feature that enables an agent-oriented perspective on automated software testing
and test-driven development. The feature allows writing test programs for Jason agents in
AgentSpeak, and aligns software testing and agent-oriented programming abstractions. This
consolidation of perspectives is called _Goal-Oriented Test-Driven Development_ (GOTDD).

== What is Goal-Oriented Test-Driven Development?
In modern software development, testing plays a key role, as it helps ensure the software works as
expected. Ideally, developers use _Test-Driven Development_ (TDD) approaches, in which a large
portion of the tests is written during or even ahead of the implementation of the actual program
code. The assumption is that specifying the exact desired behavior of a software component _before_
implementing this component facilitates a more rigorous assessment of the component and ensures
testing is not cut short because of time shortage caused by mis-estimations. Generally, it is
considered good practice to focus automated testing efforts on _unit tests_ of small components that
can and hence _should_ be tested in a rigorous manner and to cover the overall system (or system of
systems) with less dense _integration tests_ and _End-to-End_ (E2E) tests; the latter cannot cover
all possible input and environment configurations because of the explosion in combinatorial options
(even for fairly small systems) but they can potentially catch unexpected behavior of components
that seemingly work correctly from a lower-level perspective.

From an agent-oriented perspective, unit tests cover behavior that is _agent-agnostic_, _i.e._ which
can be tested as if it was a function/method call -- for example, given the internal state the agent
-- and which is disconnected from the state of the environment and the other agents that (inter)act
in it. While unit tests for agents are conceptually not different from traditional unit tests,
Jason's GOTDD feature is novel even on this level because it provides first-class abstractions for
tests in an agent-oriente programming language. Still, more interestingly, Jason allows for the
specification of tests that check whether an agent, given an initial environment state (and
potentially given other agents), will eventually (or given a specific time constraint) achieve a
particular _goal_; _i.e._, goals are promoted to first-class abstractions for test-driven
development, which allows for integration tests for single agents (agent-environment integration)
and multi agents (agent-environment-agent, whereby the environment may or may not contain explicitly
modelled artifacts) integration. The figure below shows the _test pyramid_ from a traditional
software engineering perspective and contrasts it with an agent-oriented test pyramid.

image:./figures/Agent-Oriented_TDD.png[]

The tutorial below provides examples of unit testing, single agent testing, and multi-agent testing
with Jason. Note that E2E tests are not covered, because these are typically implemented in a
different technology ecosystem (for example: _Selenium_ for end-to-end user interface testing).

== Under the Hood
Under the hood, Jason's GOTDD feature allows for the instantiation of one main agent per test file,
as well as for the instantiation of several _mock agents_; in addition to mock agents, the main
(to-be-tested) agent may interact with other agents that have been implemented in a traditional
manner. The main agent is monitored by Jason's tester agent with regards to the main agent's ability
to achieve certain goals, or the agent's internal state (for example: belief adoption). Whenever
a corresponding assertion fires, the tester agent reports the result (pass or fail). 

image:./figures/Agents-TDD-overview.png[]

== Test Levels in Jason
Now, let us provide examples how tests on the three lower levels (_unit_, _single agent_, _multi
agent_, assuming that end-to-end tests need to be supported by additional tooling) work.

=== Project Setup
Let us set up our Jason project and configure it for GOTDD.

1. First, we create a mas2j project file and specify the infrastructure type, our agents, and the
ASL source paths (see below for the unit testing example):

[source]
MAS tdd {

    infrastructure: Centralised

    agents:
        xor;

    aslSourcePath:  "src/test/jason/inc";
                    "src/test/jason/asl";
                    "src/asl";
                    "src/agt";
                    "inc";
                    "$jasonJar/test/jason/inc";
}

Then, we create the source directory structure for our project:

[source]
/
- src
    - agt
- test
    - jacamo
        - agt

As a final setup step, we create a gradle build file that allows us to test our project.
We can simply copy and adjust the file we find
link:./1_room_agent_on_jason-jacamo/build.gradle[here]. We can also create a `logging.properties`
file such as this one link:./1_room_agent_on_jason-jacamo/logging.properties[here]. 
The setup is specific to the first example (unit testing); the setup for the other test examples
differs slightly. Take a look at the example sources to make sure your setup is correct.


=== Unit Testing in Jason
Let us start by implementing a unit test that test a simple inference rule. At `src/agt`, we
create the file `room_agent.asl` and add the following rule:

[source]
now_is_warmer_than(T) :- temperature(C) & C > T.

As we can see, the rule checks if the current `temperature` is higher than some specifically
provided value. Because we merely draw inferences, but do not act in the environment, we consider'
this scenario a *unit testing* scenario and not a single agent testing scenario.

Now, we set a temperature value:

[source]
temperature(15).

Finally, we try out our inference rule:

[source]
!auto_test.

+!auto_test:
    temperature(C)
    <- 
    .print("Current temperature: ",temperature(C));

    .eval(X1, now_is_warmer_than(20));
    .print(now_is_warmer_than(20)," = ",X1);

    .eval(X2, now_is_warmer_than(10));
    .print(now_is_warmer_than(10)," = ",X2);

    .eval(X3, now_is_warmer_than(15));
    .print(now_is_warmer_than(15)," = ",X3);

Such *naive* inline tests are frequently used to facilitate debugging, but have obvious
shortcomings:

* They do not allow for a clear separation between test and production code.
* They do not clearly describe desired behavior.
* They make it hard to automate tests.

To test the file properly, we create the file `test_room_agent.asl` at `src/test/jacamo/agt`. At the
beginning of this file, we import the Jason tester agent, as well as the file that we want to test:

[source]
{ include("tester_agent.asl") }
{ include("room_agent.asl") }

Then, we add a test goal, using the `@[test]` annotation:

[source]
@[test]
+!test_now_is_warmer_than
    <-
    !assert_false(now_is_warmer_than(20));
    !assert_true(now_is_warmer_than(10));
    !assert_false(now_is_warmer_than(15));
.

As we can see, the test specifies the truth table of the inference rule, given the following three
scenarios:

1. The provided value temperature is higher than the current temperature.
2. The provided value is lower than the current temperature.
3. The provided value is equal to the current temperature.

The complete project is available link:./1_room_agent_on_jason-jacamo/[here].


=== Single Agent Testing in Jason

=== Multi-Agent Testing in Jason


== Conclusion
This tutorial has provided a brief overview of how to test Jason agents directly in AgentSpeak, as
well as of the conceptual benefits goal-oriented test-driven development provides for the
development of multi-agent systems.
